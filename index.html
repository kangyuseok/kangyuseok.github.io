<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="A study on relationship between CLIP-based zero-shot image
        classification and language-model aided visual description
        generation.">
  <meta name="keywords" content="GT, D-NeRF, NeRF">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>GT: A study on relationship between CLIP-based zero-shot image
    classification and language-model aided visual description
    generation.</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>




<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">A study on relationship between CLIP-based zero-shot image classification and language-model aided visual description generation</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://github.com/kangyuseok">kangyuseok</a><sup>1</sup>,</span>

            <span class="author-block">
              <a href="https://github.com/jeoncharn">Charn Jeon</a><sup>2</sup>,</span>

            <span class="author-block">
              <a href="https://github.com/JunyongKang">Junyong Kang</a><sup>3</sup></span>
    
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup></sup>University of Sogang,</span>
            <span class="author-block"><sup></sup>Korea</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="./static/file/research.pdf"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              
              <!-- Video Link. -->
              
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/GT-GPT/Research_Environment"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>







<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            CLIP-based zero-shot image classification calculates the similarity between the visual description and the image feature vector for the class 
            to be classified and classifies it into the class of the most similar visual description. 
          </p>
          <p>
            This study attempted to observe the correlation between the shape of the visual description sentence and the result of zero-shot image classification 
            by paying attention to the process of extracting visual description for each class through a language model.
            To this end, the example prompt given to the language model that generates visual description was classified into several options according to the description form. As a result of the experiment, 
            it was observed that 
            1) visual description in word form is preferred over sentences in CLIP-based zero-shot image classification, 
            2) performance and confidence increase according to the number of visual descriptions, and 
            3) other options do not significantly improve the quality of visual description.
          </p>
          <p>
            As a result,
1) CLIP is
We observed a correlation that word-type visual description is preferred more than sentence-type, 2) classification performance and confidence can be improved if the number of visual descriptions is large, and 3) that the number of additional commands or prompts does not significantly affect the quality of visual description.
Such observation is meaningful in suggesting guidelines for which natural language prompts should be entered from the user's point of view. Finally, in future studies, the conclusion of this study needs to be further verified by varying the structure and evaluation data set of the CLIP model.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

    
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="./static/file/research.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/GT-GPT/Research_Environment" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            This means you are free to borrow the <a
              href="https://github.com/kangyuseok/kangyuseok.github.io">source code</a> of this website,
            we just ask that you link back to this page in the footer.
            Please remember to remove the analytics code included in the header of the website which
            you do not want on your website.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
